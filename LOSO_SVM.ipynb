{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8197dfde",
   "metadata": {},
   "source": [
    "# Leave-One-Subject SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec53151",
   "metadata": {},
   "source": [
    "### Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a8e125c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a43c5c6",
   "metadata": {},
   "source": [
    "### Lists of Labels to be used for the Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b68e7792",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels1 = ['Biking', 'Downstairs', 'Jogging', 'Sitting', 'Standing', 'Upstairs', 'Walking']\n",
    "labels2 = ['Biking', 'Downstairs', 'Jogging', 'Standing_Sitting', 'Upstairs', 'Walking']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f96294",
   "metadata": {},
   "source": [
    "### Function to plot the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "010ae5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "plt.rcParams[\"font.family\"] = 'DejaVu Sans'\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    ax = plt.gca()\n",
    "    ax.set_ylim(-.5, float(len(classes))-0.5)\n",
    "        \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27618cd",
   "metadata": {},
   "source": [
    "### Generic function to run any model specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f093c3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def perform_model(model, X_train, y_train, X_test, y_test, class_labels, num, cm_normalize=True, \\\n",
    "                 print_cm=True, cm_cmap=plt.cm.Reds): #optional inputs, C_param, gamma_param, num\n",
    "    \n",
    "    \n",
    "    # to store results at various phases\n",
    "    results = dict()\n",
    "    \n",
    "    # time at which model starts training \n",
    "    train_start_time = datetime.now()\n",
    "    print('training the model for participant no.' +str(num)+ '..')\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print('Done \\n \\n')\n",
    "    train_end_time = datetime.now()\n",
    "    results['training_time'] =  train_end_time - train_start_time\n",
    "    print('training_time(HH:MM:SS.ms) - {}\\n\\n'.format(results['training_time']))\n",
    "    \n",
    "    # predict test data\n",
    "    print('Predicting test data')\n",
    "    test_start_time = datetime.now()\n",
    "    y_pred = model.predict(X_test)\n",
    "    test_end_time = datetime.now()\n",
    "    print('Done \\n \\n')\n",
    "    results['testing_time'] = test_end_time - test_start_time\n",
    "    print('testing time(HH:MM:SS:ms) - {}\\n\\n'.format(results['testing_time']))\n",
    "    results['predicted'] = y_pred\n",
    "   \n",
    "\n",
    "    # calculate overall accuracty of the model\n",
    "    accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "    # store accuracy in results\n",
    "    results['accuracy'] = accuracy\n",
    "    print('---------------------')\n",
    "    print('|      Accuracy      |')\n",
    "    print('---------------------')\n",
    "    print('\\n    {}\\n\\n'.format(accuracy))\n",
    "    \n",
    "    \n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    results['confusion_matrix'] = cm\n",
    "    if print_cm:\n",
    "        print('--------------------')\n",
    "        print('| Confusion Matrix |')\n",
    "        print('--------------------')\n",
    "        print('\\n {}'.format(cm))\n",
    "        \n",
    "    # plot confusin matrix\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.grid(visible = False)\n",
    "    plot_confusion_matrix(cm, classes=class_labels, normalize=True, title='Normalized confusion matrix', cmap = cm_cmap)\n",
    "    ax = plt.gca()\n",
    "    ax.set_ylim(-.5,float(len(class_labels))-0.5)\n",
    "    plt.show()\n",
    "    \n",
    "    # get classification report\n",
    "    print('-------------------------')\n",
    "    print('| Classifiction Report |')\n",
    "    print('-------------------------')\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    # store report in results\n",
    "    results['classification_report'] = class_report\n",
    "    print(class_report)\n",
    "    \n",
    "    # add the trained  model to the results\n",
    "    results['model'] = model\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d67fc82",
   "metadata": {},
   "source": [
    "### Method to print the Grid Search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cfc71f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_grid_search_attributes(model, num): #or 'results' as input\n",
    "    print('grid search for participant no.' +str(num)+ '..')\n",
    "    print('Done \\n \\n')\n",
    "    \n",
    "    # Estimator that gave highest score among all the estimators formed in GridSearch\n",
    "    print('--------------------------')\n",
    "    print('|      Best Estimator     |')\n",
    "    print('--------------------------')\n",
    "    \n",
    "    \n",
    "    print('\\n\\t{}\\n'.format(model.best_estimator_))\n",
    "    best_estimator = model.best_estimator_\n",
    "\n",
    "\n",
    "    # parameters that gave best results while performing grid search\n",
    "    print('--------------------------')\n",
    "    print('|     Best parameters     |')\n",
    "    print('--------------------------')\n",
    "                                                               \n",
    "    \n",
    "    print('\\tParameters of best estimator : \\n\\n\\t{}\\n'.format(model.best_params_))\n",
    "    best_params = model.best_params_\n",
    "\n",
    "\n",
    "    #  number of cross validation splits\n",
    "    print('---------------------------------')\n",
    "    print('|   No of CrossValidation sets   |')\n",
    "    print('--------------------------------')\n",
    "    print('\\n\\tTotal number of cross validation sets: {}\\n'.format(model.n_splits_))\n",
    "\n",
    "\n",
    "    # Average cross validated score of the best estimator, from the Grid Search \n",
    "    print('--------------------------')\n",
    "    print('|        Best Score       |')\n",
    "    print('--------------------------')\n",
    "    \n",
    "    \n",
    "    print('\\n\\tAverage Cross Validate scores of best estimator : \\n\\n\\t{}\\n'.format(model.best_score_))\n",
    "    \n",
    "    return best_estimator, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f031f874",
   "metadata": {},
   "source": [
    "### LOSO SVM function - along with a grid search for the optimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ed0f522",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that finds the most common element in a list\n",
    "def most_common(List):\n",
    "    count = Counter(List)\n",
    "    return count.most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01f7b18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.makedirs('LOSO_SVM/confusion_matrices', exist_ok=True)\n",
    "\n",
    "def LOSO_SVM():\n",
    "    \n",
    "    #lists to store the confusion matrix and accuracy for each participant\n",
    "    cm_list = []\n",
    "    acc_list = []\n",
    "    \n",
    "    #list to store the predicted values and the test values\n",
    "    yTest = []\n",
    "    yPred = []\n",
    "    \n",
    "    #list to store the optimal parameters and the best model\n",
    "    best_parameters = []\n",
    "    best_estimators = []\n",
    "    \n",
    "    #the first 'for' loop validates the optimal parameters using the LOSO cross validation\n",
    "    for i in range(0, 10):\n",
    "        X_train = pd.read_csv('train_test_dataset/X_train_fold_' +str(i+1)+ '.csv').values\n",
    "        X_test = pd.read_csv('train_test_dataset/X_test_fold_' +str(i+1)+ '.csv').values\n",
    "        y_train = pd.read_csv('train_test_dataset/y_train_fold_' +str(i+1)+ '.csv').values.ravel()\n",
    "        y_test = pd.read_csv('train_test_dataset/y_test_fold_' +str(i+1)+ '.csv').values.ravel()\n",
    "        \n",
    "        parameters = {'C': [1], 'gamma': [1.2]}\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_train_norm = scaler.fit_transform(X_train)\n",
    "        X_test_norm = scaler.transform(X_test)\n",
    "        \n",
    "        rbf_svm = SVC(kernel = 'rbf')\n",
    "        rbf_svm_grid = GridSearchCV(rbf_svm, scoring='accuracy', param_grid=parameters, cv=10, n_jobs=-1)\n",
    "        rbf_svm_grid.fit(X_train_norm, y_train)\n",
    "        ypred = rbf_svm_grid.predict(X_test)\n",
    "\n",
    "        optimal_estim, optimal_param = print_grid_search_attributes(rbf_svm_grid, i+1)\n",
    "        \n",
    "        best_parameters.append(optimal_param)\n",
    "        best_estimators.append(optimal_estim)\n",
    "    \n",
    "    #in the second 'for' loop we train the model with the optimal parameters\n",
    "    for j in range(10):\n",
    "        X_train = pd.read_csv('train_test_dataset/X_train_fold_' +str(j+1)+ '.csv').values\n",
    "        X_test = pd.read_csv('train_test_dataset/X_test_fold_' +str(j+1)+ '.csv').values\n",
    "        y_train = pd.read_csv('train_test_dataset/y_train_fold_' +str(j+1)+ '.csv').values.ravel()\n",
    "        y_test = pd.read_csv('train_test_dataset/y_test_fold_' +str(j+1)+ '.csv').values.ravel()\n",
    "        \n",
    "        scaler = MinMaxScaler()\n",
    "        X_train_norm = scaler.fit_transform(X_train)\n",
    "        X_test_norm = scaler.transform(X_test)\n",
    "        \n",
    "        best_rbf_svm = most_common(best_estimators)\n",
    "        best_rbf_svm_results = perform_model(best_rbf_svm, X_train_norm, y_train, X_test_norm, y_test,\\\n",
    "                                class_labels=labels1, num=j+1)\n",
    "        \n",
    "        y_pred = best_rbf_svm_results['predicted']\n",
    "        \n",
    "        yTest.extend(y_test)\n",
    "        yPred.extend(y_pred)\n",
    "        \n",
    "        cm = best_rbf_svm_results['confusion_matrix']\n",
    "        #np.savetxt('LOSO_SVM/confusion_matrices/cm_' +str(j+1)+ '.csv', cm, delimiter=',')\n",
    "        acc = best_rbf_svm_results['accuracy']\n",
    "        \n",
    "        cm_list.append(cm)\n",
    "        acc_list.append(acc)\n",
    "        \n",
    "    return cm_list, yTest, yPred, best_rbf_svm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c4c30be",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid search for participant no.1..\n",
      "Done \n",
      " \n",
      "\n",
      "--------------------------\n",
      "|      Best Estimator     |\n",
      "--------------------------\n",
      "\n",
      "\tSVC(C=1, gamma=1.2)\n",
      "\n",
      "--------------------------\n",
      "|     Best parameters     |\n",
      "--------------------------\n",
      "\tParameters of best estimator : \n",
      "\n",
      "\t{'C': 1, 'gamma': 1.2}\n",
      "\n",
      "---------------------------------\n",
      "|   No of CrossValidation sets   |\n",
      "--------------------------------\n",
      "\n",
      "\tTotal number of cross validation sets: 10\n",
      "\n",
      "--------------------------\n",
      "|        Best Score       |\n",
      "--------------------------\n",
      "\n",
      "\tAverage Cross Validate scores of best estimator : \n",
      "\n",
      "\t0.3909171075837742\n",
      "\n",
      "grid search for participant no.2..\n",
      "Done \n",
      " \n",
      "\n",
      "--------------------------\n",
      "|      Best Estimator     |\n",
      "--------------------------\n",
      "\n",
      "\tSVC(C=1, gamma=1.2)\n",
      "\n",
      "--------------------------\n",
      "|     Best parameters     |\n",
      "--------------------------\n",
      "\tParameters of best estimator : \n",
      "\n",
      "\t{'C': 1, 'gamma': 1.2}\n",
      "\n",
      "---------------------------------\n",
      "|   No of CrossValidation sets   |\n",
      "--------------------------------\n",
      "\n",
      "\tTotal number of cross validation sets: 10\n",
      "\n",
      "--------------------------\n",
      "|        Best Score       |\n",
      "--------------------------\n",
      "\n",
      "\tAverage Cross Validate scores of best estimator : \n",
      "\n",
      "\t0.3886243386243386\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cm, yTest, yPred, best_estimator \u001b[38;5;241m=\u001b[39m \u001b[43mLOSO_SVM\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [7], line 32\u001b[0m, in \u001b[0;36mLOSO_SVM\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m rbf_svm \u001b[38;5;241m=\u001b[39m SVC(kernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrbf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     31\u001b[0m rbf_svm_grid \u001b[38;5;241m=\u001b[39m GridSearchCV(rbf_svm, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, param_grid\u001b[38;5;241m=\u001b[39mparameters, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m \u001b[43mrbf_svm_grid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m ypred \u001b[38;5;241m=\u001b[39m rbf_svm_grid\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     35\u001b[0m optimal_estim, optimal_param \u001b[38;5;241m=\u001b[39m print_grid_search_attributes(rbf_svm_grid, i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1387\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cm, yTest, yPred, best_estimator = LOSO_SVM()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb05f29",
   "metadata": {},
   "source": [
    "### Method to save the y_test and y_pred results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe3147b",
   "metadata": {},
   "source": [
    "Run the following code snippet if you wish to run the whole file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f7e121",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.makedirs('LOSO_SVM/test_y_pred', exist_ok=True)\n",
    "\n",
    "#with open('LOSO_SVM/test_y_pred/yTest.csv', 'w', newline='') as file:\n",
    "#    writer = csv.writer(file)\n",
    "    \n",
    "#    for item in yTest:\n",
    "#        writer.writerow([item])\n",
    "        \n",
    "#with open('LOSO_SVM/test_y_pred/yPred.csv', 'w', newline='') as file:\n",
    "#    writer = csv.writer(file)\n",
    "    \n",
    "#    for item in yPred:\n",
    "#        writer.writerow([item])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83568818",
   "metadata": {},
   "source": [
    "### Method to load the y_test and y_pred results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f0f9d8",
   "metadata": {},
   "source": [
    "Run the following code snippet if you just wish to load the files from the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a429ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#yTest=[]\n",
    "#with open('LOSO_SVM/test_y_pred/yTest.csv', 'r') as file:\n",
    "#    reader = csv.reader(file)\n",
    "#    for row in reader:\n",
    "#        yTest.append(row[0])\n",
    "#\n",
    "#yPred=[]\n",
    "#with open('LOSO_SVM/test_y_pred/yPred.csv', 'r') as file:\n",
    "#    reader = csv.reader(file)\n",
    "#    for row in reader:\n",
    "#        yPred.append(row[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5720eb8",
   "metadata": {},
   "source": [
    "### Method to print the Confusion Matrix of all participants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3891c8",
   "metadata": {},
   "source": [
    "If the user wishes to run the whole file, he should unpin the '#' comment line and pin as comments the '#<---#' lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac638684",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "complete_conf_matrix = cm[0] + cm[1] + cm[2] + cm[3] + cm[4] + cm[5] + cm[6] + cm[7] + cm[8] + cm[9]\n",
    "\n",
    "#cm_list = [] #<---#\n",
    "#for i in range(10): #<---#\n",
    "#    cm = np.loadtxt('LOSO_SVM/confusion_matrices/cm_' +str(i+1)+ '.csv', delimiter=',').astype(np.int64) #<---#\n",
    "#    cm_list.append(cm) #<---#\n",
    "    \n",
    "#complete_conf_matrix = np.sum(cm_list, axis=0) #<---#\n",
    "\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.grid(visible = False)\n",
    "plot_confusion_matrix(complete_conf_matrix, classes=labels1, normalize=True, title='Normalized confusion matrix', cmap = plt.cm.Reds)\n",
    "ax = plt.gca()\n",
    "ax.set_ylim(-.5,6.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c013e4",
   "metadata": {},
   "source": [
    "### Code snippet to print the middle accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57013017",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('-------------------')\n",
    "print('| Middle Accuracy |')\n",
    "print('-------------------')\n",
    "middle_acc = complete_conf_matrix.diagonal() / complete_conf_matrix.sum(axis = 1)\n",
    "print(middle_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd5570c",
   "metadata": {},
   "source": [
    "### Code snippet to print the Classification Report for all participans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec792328",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('----------------------------------------------')\n",
    "print('| Classification Report for all Participants |')\n",
    "print('----------------------------------------------')\n",
    "cr = classification_report(yTest, yPred, target_names=labels1)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5757b93f",
   "metadata": {},
   "source": [
    "### Code snippet to print the accuracy for all participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84125d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('---------------------------------')\n",
    "print('| Accuracy for all Participants |')\n",
    "print('---------------------------------')\n",
    "acc_score = accuracy_score(yTest, yPred)\n",
    "print('\\n\\t{}\\n'.format(acc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13790fa8",
   "metadata": {},
   "source": [
    "### LOSO SVM Function of the regrouped dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6159fa13",
   "metadata": {},
   "source": [
    "The parameters that are used to train and test the classifier are the optimal parameters that are found in the grid search above. After noticing that the algorithm confuses the 'walking' and 'standing' classes we joined those classes and performed LOSO Cross Validation to the regrouped dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b386f0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.makedirs('LOSO_SVM/regrouped_confusion_matrices', exist_ok=True)\n",
    "\n",
    "def LOSO_SVM_REGROUPED():\n",
    "    \n",
    "    cm_list = []\n",
    "    acc_list = []\n",
    "    \n",
    "    yTest = []\n",
    "    yPred = []\n",
    "    \n",
    "    for i in range(0, 10):\n",
    "        X_train = pd.read_csv('train_test_dataset/X_train_fold_' +str(i+1)+ '.csv').values\n",
    "        X_test = pd.read_csv('train_test_dataset/X_test_fold_' +str(i+1)+ '.csv').values\n",
    "        y_train = pd.read_csv('regrouped_dataset/y_train_' +str(i+1)+ '_regrouped.csv').values.ravel()\n",
    "        y_test = pd.read_csv('regrouped_dataset/y_test_' +str(i+1)+ '_regrouped.csv').values.ravel()\n",
    "        \n",
    "        scaler = MinMaxScaler()\n",
    "        X_train_norm = scaler.fit_transform(X_train)\n",
    "        X_test_norm = scaler.transform(X_test)\n",
    "        \n",
    "        rbf_svm = best_estimator\n",
    "        rbf_svm_results = perform_model(rbf_svm, X_train_norm, y_train, X_test_norm, y_test,\\\n",
    "                                             class_labels=labels2, num=i+1)\n",
    "        \n",
    "        y_pred = rbf_svm_results['predicted']\n",
    "        \n",
    "        yTest.extend(y_test)\n",
    "        yPred.extend(y_pred)\n",
    "        \n",
    "        cm = rbf_svm_results['confusion_matrix']\n",
    "        #np.savetxt('LOSO_SVM/regrouped_confusion_matrices/cm_' +str(i+1)+ '_regrouped.csv', cm, delimiter=',')\n",
    "        acc = rbf_svm_results['accuracy']\n",
    "        \n",
    "        cm_list.append(cm)\n",
    "        acc_list.append(acc)\n",
    "        \n",
    "    return cm_list, yTest, yPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c112a2e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cm_list_regrouped, yTest_regrouped, yPred_regrouped = LOSO_SVM_REGROUPED()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d1b398",
   "metadata": {},
   "source": [
    "### Method for saving the yTest_regrouped and yPred_regrouped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cebd769",
   "metadata": {},
   "source": [
    "Run the following code snippet if you wish to run the whole file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3404d119",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.makedirs('LOSO_SVM/test_y_pred', exist_ok=True)\n",
    "\n",
    "#with open('LOSO_SVM/test_y_pred/yTest_regrouped.csv', 'w', newline='') as file:\n",
    "#    writer = csv.writer(file)\n",
    "    \n",
    "#    for item in yTest_regrouped:\n",
    "#        writer.writerow([item])\n",
    "        \n",
    "#with open('LOSO_SVM/test_y_pred/yPred_regrouped.csv', 'w', newline='') as file:\n",
    "#    writer = csv.writer(file)\n",
    "    \n",
    "#    for item in yPred_regrouped:\n",
    "#        writer.writerow([item])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0e22b2",
   "metadata": {},
   "source": [
    "### Method for loading yTest_regrouped and yPred_regrouped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d590313a",
   "metadata": {},
   "source": [
    "Run the following code snippet if you just wish to load the files from the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fee3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#yTest_regrouped = []\n",
    "#with open('LOSO_SVM/test_y_pred/yTest_regrouped.csv', 'r') as file:\n",
    "#    reader = csv.reader(file)\n",
    "#    for row in reader:\n",
    "#        yTest_regrouped.append(row[0])\n",
    "\n",
    "#yPred_regrouped = []\n",
    "#with open('LOSO_SVM/test_y_pred/yPred_regrouped.csv', 'r') as file:\n",
    "#    reader = csv.reader(file)\n",
    "#    for row in reader:\n",
    "#        yPred_regrouped.append(row[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00031da",
   "metadata": {},
   "source": [
    "### Method for printing the regrouped Confusion Matrix for all participants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0359d10",
   "metadata": {},
   "source": [
    "If the user wishes to run the whole file, he should unpin the '#' comment line and pin as comments the '#<---#' lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f7236a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cm_regrouped = cm_list_regrouped[0] + cm_list_regrouped[1] + cm_list_regrouped[2] + cm_list_regrouped[3] + cm_list_regrouped[4] + cm_list_regrouped[5] + cm_list_regrouped[6] + cm_list_regrouped[7] + cm_list_regrouped[8] + cm_list_regrouped[9]\n",
    "\n",
    "#cm_list_regrouped = [] #<---#\n",
    "#for i in range(10): #<---#\n",
    "#    matrix = np.loadtxt('LOSO_SVM/regrouped_confusion_matrices/cm_' +str(i+1)+ '_regrouped.csv', delimiter=',').astype(np.int64) #<---#\n",
    "#    cm_list_regrouped.append(matrix) #<---#\n",
    "    \n",
    "#cm_regrouped = np.sum(cm_list_regrouped, axis=0) #<---#\n",
    "    \n",
    "\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.grid(visible = False)\n",
    "plot_confusion_matrix(cm_regrouped, classes=labels2, normalize=True, title='Normalized confusion matrix', cmap = plt.cm.Reds)\n",
    "ax = plt.gca()\n",
    "ax.set_ylim(-.5,5.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50acca93",
   "metadata": {},
   "source": [
    "### Code snippet to print the Classification Report of the regrouped dataset for all participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29869d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('----------------------------------------------')\n",
    "print('| Classification Report for all Participants |')\n",
    "print('----------------------------------------------')\n",
    "cr_regrouped = classification_report(yTest_regrouped, yPred_regrouped, target_names=labels2)\n",
    "print(cr_regrouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33be4905",
   "metadata": {},
   "source": [
    "### Code snippet to print the accuracy of the regrouped dataset for all participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a35e6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('---------------------------------')\n",
    "print('| Accuracy for all Participants |')\n",
    "print('---------------------------------')\n",
    "acc_score = accuracy_score(yTest_regrouped, yPred_regrouped)\n",
    "print('\\n\\t{}\\n'.format(acc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40542c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_estimator(n):\n",
    "    train_x = pd.read_csv('10_Subject_Dataset/X_train.csv').values\n",
    "    train_y = pd.read_csv('10_Subject_Dataset/y_train.csv').values\n",
    "    \n",
    "    participant_l = pd.read_csv('dataset/Left_Pocket_Dataset/Participant_' +str(n)+ '_left.csv')\n",
    "    x_left = participant_l.iloc[:, :-1].values\n",
    "    y_left = participant_l.iloc[:, -1].values\n",
    "    \n",
    "    participant_w = pd.read_csv('dataset/Wrist_Dataset/Participant_' +str(n)+ '_wrist.csv')\n",
    "    x_wrist = participant_w.iloc[:, :-1].values\n",
    "    y_wrist = participant_w.iloc[:, -1].values\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    train_x = scaler.fit_transform(train_x)\n",
    "    x_left = scaler.transform(x_left)\n",
    "    x_wrist = scaler.transform(x_wrist)\n",
    "    \n",
    "    model = best_estimator\n",
    "    model.fit(train_x, train_y)\n",
    "    \n",
    "    prediction_left = model.predict(x_left)\n",
    "    prediction_wrist = model.predict(x_wrist)\n",
    "    \n",
    "    return prediction_left, prediction_wrist, y_left, y_wrist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42e72bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prediction_left, prediction_wrist, y_left, y_wrist = optimal_estimator(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056104e4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cm_left = confusion_matrix(y_left, prediction_left)\n",
    "\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.grid(visible = False)\n",
    "plot_confusion_matrix(cm_left, classes=labels1, normalize=True, title='Normalized confusion matrix', cmap = plt.cm.Reds)\n",
    "ax = plt.gca()\n",
    "ax.set_ylim(-.5,6.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed27c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('----------------------------------------------')\n",
    "print('| Classification Report for all Participants |')\n",
    "print('----------------------------------------------')\n",
    "cr_left = classification_report(y_left, prediction_left, target_names=labels1)\n",
    "print(cr_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78681c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('---------------------------------')\n",
    "print('| Accuracy for all Participants |')\n",
    "print('---------------------------------')\n",
    "acc_score = accuracy_score(y_left, prediction_left)\n",
    "print('\\n\\t{}\\n'.format(acc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23da98a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cm_wrist = confusion_matrix(y_wrist, prediction_wrist)\n",
    "\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.grid(visible = False)\n",
    "plot_confusion_matrix(cm_wrist, classes=labels1, normalize=True, title='Normalized confusion matrix', cmap = plt.cm.Reds)\n",
    "ax = plt.gca()\n",
    "ax.set_ylim(-.5,6.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc941bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('----------------------------------------------')\n",
    "print('| Classification Report for all Participants |')\n",
    "print('----------------------------------------------')\n",
    "cr_wrist = classification_report(y_wrist, prediction_wrist, target_names=labels1)\n",
    "print(cr_wrist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83b69a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('---------------------------------')\n",
    "print('| Accuracy for all Participants |')\n",
    "print('---------------------------------')\n",
    "acc_score = accuracy_score(y_wrist, prediction_wrist)\n",
    "print('\\n\\t{}\\n'.format(acc_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
